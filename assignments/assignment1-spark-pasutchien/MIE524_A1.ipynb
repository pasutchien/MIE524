{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MIE524 - Assignment 1\n"
      ],
      "metadata": {
        "id": "P3rGTK43YrNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "sk5Fl4bBY4k5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set up Spark on your Colab environment.  Run the cell below!"
      ],
      "metadata": {
        "id": "KVBFUi_sY_Rl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV-AdHT2Yk_4",
        "outputId": "bb239726-146c-42c6-f2cc-295768e23553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=56eec53fb07f311b79bc13e6336616581be135a50ac3d76c61fc8af82f2641c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 28 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 122532 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ],
      "metadata": {
        "id": "cCNkNzbNZEOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "import pandas as pd\n",
        "\n",
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "LFZXyGgJZISe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put all your imports, and path constants in the next cells."
      ],
      "metadata": {
        "id": "3flXijoNxGW5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZlFnHCuxPik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1 - Message Count in Spark"
      ],
      "metadata": {
        "id": "zBzZCFTUZVIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset"
      ],
      "metadata": {
        "id": "NG8u58Eh3onu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "pSLA9G5UZBI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first make sure to upload the werkmap_messages.csv file from the data folder of your starter repository to colab's files\n",
        "werkmap_message_data = 'werkmap_messages.csv'"
      ],
      "metadata": {
        "id": "z8-4i36t9AVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you executed the cells above, you should be able to see the file *plotsummaries.txt* under the \"Files\" tab on the left panel."
      ],
      "metadata": {
        "id": "Zy7nM4ltZP3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write your function in the next cells"
      ],
      "metadata": {
        "id": "APxI9MCs4Ovz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_month_year(row):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        row : a row of the input data\n",
        "    OUTPUT:\n",
        "        month_year : string\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "# You may have additional functions or modify the provided functions as necessary"
      ],
      "metadata": {
        "id": "82TmJ8Ii3u4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run your function in the next cells to output required content."
      ],
      "metadata": {
        "id": "tcXHqu7q6IwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAIIrExX5_H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 2 - Oxford Covid-19 Government Response Tracker"
      ],
      "metadata": {
        "id": "pYACdWmz6MUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset"
      ],
      "metadata": {
        "id": "7Cvzdbj37zyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id='1GuUEDg3ZZ9c-8k7ZwDq_Y9WcZlDT65S-'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('OxCGRT_USA_latest.csv')"
      ],
      "metadata": {
        "id": "rfUnVaKo6WaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2 - Computing Index Score with Spark"
      ],
      "metadata": {
        "id": "GFUIJwlD8KiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        df: spark dataframe\n",
        "    OUTPUT:\n",
        "        cleaned data: spark dataframe\n",
        "\n",
        "    NOTE: output the given word with characters stripped.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "def impute_data(df):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        df: spark dataframe\n",
        "    OUTPUT:\n",
        "        imputed data: spark dataframe\n",
        "\n",
        "    NOTE: output the dataframe with nan values replaced with the minimal value of the given indicator.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "def group_and_aggregate_data(df):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        df: spark dataframe\n",
        "    OUTPUT:\n",
        "        groupe and aggregated data: spark dataframe\n",
        "\n",
        "    NOTE: output the dataframe with grouped (by month) and aggregated (based on the algorithm) data.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "def compute_index_score(df):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        df: spark dataframe\n",
        "    OUTPUT:\n",
        "        list of index scores per region and period: list\n",
        "\n",
        "    NOTE: output a list of computed scores per region and period based on the algorithm.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "# You may have additional functions"
      ],
      "metadata": {
        "id": "G4VuOGh78O4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You may use below lists to get indicators and flags header\n",
        "indicators = [\"C1M_School closing\",\n",
        "\"C2M_Workplace closing\",\n",
        "\"C3M_Cancel public events\",\n",
        "\"C4M_Restrictions on gatherings\",\n",
        "\"C5M_Close public transport\",\n",
        "\"C6M_Stay at home requirements\",\n",
        "\"C7M_Restrictions on internal movement\",\n",
        "\"C8EV_International travel controls\",\n",
        "\"E1_Income support\",\n",
        "\"E2_Debt/contract relief\",\n",
        "\"H1_Public information campaigns\",\n",
        "\"H2_Testing policy\",\n",
        "\"H3_Contact tracing\",\n",
        "\"H6M_Facial Coverings\",\n",
        "\"H7_Vaccination policy\",\n",
        "\"H8M_Protection of elderly people\"]\n",
        "\n",
        "indicator_flags = [\"C1M_Flag\",\n",
        "\"C2M_Flag\",\n",
        "\"C3M_Flag\",\n",
        "\"C4M_Flag\",\n",
        "\"C5M_Flag\",\n",
        "\"C6M_Flag\",\n",
        "\"C7M_Flag\",\n",
        "\"E1_Flag\",\n",
        "\"H1_Flag\",\n",
        "\"H6M_Flag\",\n",
        "\"H7_Flag\",\n",
        "\"H8M_Flag\"]"
      ],
      "metadata": {
        "id": "aqQjGWmB7ykZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run your function in the next cells to output required content."
      ],
      "metadata": {
        "id": "rEocWs4stsKs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OReazs5stsbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3 - Association Rules"
      ],
      "metadata": {
        "id": "7d6NcDhRtuTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_items(df):\n",
        "    \"\"\"\n",
        "      INPUT:\n",
        "          df: spark dataframe\n",
        "      OUTPUT:\n",
        "          list itemsets: list\n",
        "\n",
        "      NOTE: output a list itemsets from given dataframe.\n",
        "      \"\"\"\n",
        "      # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "m4okMWMT8ApT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apriori(items, min_sup, itemset_size):\n",
        "    \"\"\"\n",
        "    INPUT:\n",
        "        items: list\n",
        "        min_sup: the min support\n",
        "    OUTPUT:\n",
        "        list of frequent itemsets: list\n",
        "\n",
        "    NOTE: output a list of frequent itemsets.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "# You may have additional functions"
      ],
      "metadata": {
        "id": "jYTwc9Cgtw87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run your function in the next cells to output required content."
      ],
      "metadata": {
        "id": "YCZOK6SIxfXg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ccexb2wsxgxn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}